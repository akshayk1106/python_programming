{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6582e818-7e3f-403f-b5c4-d77f5ae9a2c1",
   "metadata": {},
   "source": [
    "### <mark> df.show(n=20, truncate=20, vertical=False)\n",
    "\n",
    "PySpark DataFrame show() is used to display the contents of the DataFrame in a Table Row and Column Format. By default, it shows only 20 Rows, and the column values are truncated at 20 characters.\n",
    "\n",
    "Use PySpark show() method to display the contents of the DataFrame and use pyspark printSchema() method to print the schema.\n",
    "\n",
    "    # Default - displays 20 rows and 20 charactes from column value \n",
    "    df.show()\n",
    "\n",
    "    # Display full column contents\n",
    "    df.show(truncate=False)\n",
    "\n",
    "    # Display 2 rows and full column contents\n",
    "    df.show(2,truncate=False) \n",
    "\n",
    "    # Display 2 rows & column values 25 characters\n",
    "    df.show(2,truncate=25) \n",
    "\n",
    "    # Display DataFrame rows & columns vertically\n",
    "    df.show(n=3,truncate=25,vertical=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb14262-ad12-48f6-96d6-7732daef3944",
   "metadata": {},
   "source": [
    "### <mark> df.printSchema()\n",
    "\n",
    "    root\n",
    "     |-- firstname: string (nullable = true)\n",
    "     |-- middlename: string (nullable = true)\n",
    "     |-- lastname: string (nullable = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d552bb30-0da3-4fae-8082-4272b69e6af8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <mark> from pyspark.sql.types import StructType, StructField, StringType\n",
    "    \n",
    "PySpark infers a schema from data, sometimes we may need to define our own column names and data types. PySpark StructType & StructField classes are used to programmatically specify the schema to the DataFrame and create complex columns like nested struct, array, and map columns. StructType is a collection of StructField’s that defines column name, column data type, boolean to specify if the field can be nullable or not and metadata. \n",
    "\n",
    "    from pyspark.sql.types import (\n",
    "        StructType,\n",
    "        StructField, \n",
    "        StringType, \n",
    "        IntegerType,\n",
    "        ArrayType,\n",
    "        MapType,\n",
    "        )  \n",
    "    \n",
    "    schema = StructType([ \\\n",
    "        StructField(\"firstname\",StringType(),True), \\\n",
    "        StructField(\"middlename\",StringType(),True), \\\n",
    "      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fc172e-1ed5-4b41-8de2-ecb39c9a15c2",
   "metadata": {},
   "source": [
    "#### arrayType and mapType    \n",
    "    \n",
    "    arrayStructureSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "           StructField('firstname', StringType(), True),\n",
    "           StructField('middlename', StringType(), True),\n",
    "           StructField('lastname', StringType(), True)\n",
    "           ])),\n",
    "           StructField('hobbies', ArrayType(StringType()), True),\n",
    "           StructField('properties', MapType(StringType(),StringType()), True)\n",
    "        ])\n",
    "\n",
    "\n",
    "    root\n",
    "     |-- name: struct (nullable = true)\n",
    "     |    |-- firstname: string (nullable = true)\n",
    "     |    |-- middlename: string (nullable = true)\n",
    "     |    |-- lastname: string (nullable = true)\n",
    "     |-- hobbies: array (nullable = true)\n",
    "     |    |-- element: string (containsNull = true)\n",
    "     |-- properties: map (nullable = true)\n",
    "     |    |-- key: string\n",
    "     |    |-- value: string (valueContainsNull = true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee16aac8-930b-4807-b9c8-71d2ff086dbf",
   "metadata": {},
   "source": [
    "#### nestedSchema\n",
    "    \n",
    "    nestedSchema = StructType([\n",
    "        StructField('name', StructType([\n",
    "             StructField('firstname', StringType(), True),\n",
    "             StructField('lastname', StringType(), True)\n",
    "             ])),\n",
    "         StructField('salary', IntegerType(), True)\n",
    "         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df424ab-6874-44e8-a93c-3b31bf310428",
   "metadata": {},
   "source": [
    "#### adding & changing struct of the DataFrame\n",
    "\n",
    "    from pyspark.sql.functions import col,struct,when\n",
    "    updatedDF = df2.withColumn(\"OtherInfo\", \n",
    "        struct(col(\"id\").alias(\"identifier\"),\n",
    "        col(\"gender\").alias(\"gender\"),\n",
    "        col(\"salary\").alias(\"salary\"),\n",
    "        when(col(\"salary\").cast(IntegerType()) < 2000,\"Low\")\n",
    "          .when(col(\"salary\").cast(IntegerType()) < 4000,\"Medium\")\n",
    "          .otherwise(\"High\").alias(\"Salary_Grade\")\n",
    "      )).drop(\"id\",\"gender\",\"salary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59a61c62-aa1d-4b34-80bb-a7660979af51",
   "metadata": {},
   "source": [
    "#### <mark> df.schema\n",
    "\n",
    "#### Creating StructType object struct from JSON file\n",
    "\n",
    "If you have too many columns and the structure of the DataFrame changes now and then, it’s a good practice to load the SQL StructType schema from JSON file. You can get the schema by using df2.schema.json() , store this in a file and will use it to create a the schema from this file.\n",
    "\n",
    "    > print(df2.schema.json())\n",
    "\n",
    "    > df.schema.simpleString() \n",
    "    # this will return relatively simple schema format\n",
    "\n",
    "    > import json\n",
    "    > schemaFromJson = StructType.fromJson(json.loads(schema.json))\n",
    "    > name_rdd = spark.sparkContext.parallelize(name_data)\n",
    "    > df3 = spark.createDataFrame(name_rdd,schemaFromJson)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25e6ef-610f-44bd-9680-edccbcbbe6dd",
   "metadata": {},
   "source": [
    "### Checking if a Column Exists in a DataFrame\n",
    "\n",
    "\n",
    "    > df.schema.fieldNames.contains(\"firstname\")\n",
    "\n",
    "    > df.schema.contains(StructField(\"firstname\",StringType,true))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0bae090-7e6f-4922-abc0-eac6bbbeda1b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ccccd7b-a613-460f-a127-28d19eee4e94",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd2063c1-07a7-473e-898f-8c3de474c53c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71baf1fd-393c-4ba2-a3db-a8a907769157",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6734b2c1-08bd-4edf-9da9-78b983268fa1",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
